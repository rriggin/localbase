#!/usr/bin/env python3
"""
Debug and Fix Script

Fixes schema expansion and API issues.
"""

import sys
import os
import time
import requests

# Add the project root to the path
sys.path.append(os.path.join(os.path.dirname(__file__), '../../../'))

# Load environment variables
from config.env import load_env
load_env()

from supabase import create_client, Client

def debug_api_connection():
    """Debug the RoofMaxx API connection."""
    
    print("üîç DEBUGGING ROOFMAXX API")
    print("-" * 40)
    
    token = os.getenv('ROOFMAXX_CONNECT_TOKEN')
    base_url = os.getenv('ROOFMAXX_CONNECT_BASE_URL')
    dealer_id = os.getenv('ROOFMAXX_CONNECT_DEALER_ID')
    
    print(f"üåê Base URL: {base_url}")
    print(f"üÜî Dealer ID: {dealer_id}")
    print(f"üîë Token: {token[:20]}..." if token else "‚ùå No token")
    
    headers = {
        'Authorization': f'Bearer {token}',
        'Accept': 'application/json',
        'Content-Type': 'application/json'
    }
    
    # Test different endpoints
    endpoints_to_test = [
        f"/api/dealers/{dealer_id}/deals",
        f"/api/dealers/{dealer_id}/deals?page=1",
        f"/api/dealers/{dealer_id}",  # Test dealer info first
        "/api/dealers",  # Test general dealers endpoint
    ]
    
    for endpoint in endpoints_to_test:
        try:
            url = f"{base_url}{endpoint}"
            print(f"\nüß™ Testing: {endpoint}")
            print(f"üì° Full URL: {url}")
            
            response = requests.get(url, headers=headers, timeout=10)
            
            print(f"üìä Status: {response.status_code}")
            
            if response.status_code == 200:
                data = response.json()
                print(f"‚úÖ SUCCESS! Got data:")
                
                if 'data' in data:
                    print(f"   üìà Records: {len(data['data'])}")
                    if data['data']:
                        print(f"   üîç First record keys: {list(data['data'][0].keys())}")
                
                if 'meta' in data:
                    meta = data['meta']
                    print(f"   üìÑ Pagination: page {meta.get('current_page', 'N/A')} of {meta.get('last_page', 'N/A')}")
                    print(f"   üìä Total: {meta.get('total', 'N/A')}")
                
                return endpoint, data
                
            elif response.status_code == 404:
                print(f"‚ùå 404 Not Found")
            elif response.status_code == 401:
                print(f"‚ùå 401 Unauthorized - Check API token")
            else:
                print(f"‚ùå Error {response.status_code}: {response.text[:200]}")
                
        except Exception as e:
            print(f"‚ùå Exception: {e}")
    
    return None, None

def add_columns_to_table():
    """Add columns to the existing table using ALTER TABLE."""
    
    print("üîß ADDING COLUMNS TO TABLE")
    print("-" * 40)
    
    # We'll add columns one by one by inserting records that fail gracefully
    url = os.getenv('SUPABASE_URL') 
    key = os.getenv('SUPABASE_SERVICE_ROLE_KEY')
    
    try:
        client = create_client(url, key)
        
        # First, let's see what columns exist
        print("üîç Checking current table structure...")
        
        # Insert minimal data first
        basic_data = {'deal_id': 999999998}
        
        try:
            result = client.table('roofmaxx_deals').upsert(basic_data).execute()
            print("‚úÖ Basic insert works")
            
            # Clean up
            client.table('roofmaxx_deals').delete().eq('deal_id', 999999998).execute()
            
        except Exception as e:
            print(f"‚ùå Basic insert failed: {e}")
            return False
        
        # Now try adding more fields progressively
        fields_to_add = [
            ('dealer_id', 6637),
            ('deal_type', 'Test'),
            ('deal_lifecycle', 'Test'),
            ('deal_stage', 'Test'),
            ('customer_first_name', 'Test'),
            ('customer_last_name', 'Test'),
            ('city', 'Test'),
            ('state', 'TX'),
        ]
        
        working_data = {'deal_id': 999999997}
        
        for field_name, field_value in fields_to_add:
            try:
                test_data = working_data.copy()
                test_data[field_name] = field_value
                
                print(f"   üß™ Testing field: {field_name}")
                
                result = client.table('roofmaxx_deals').upsert(test_data).execute()
                working_data[field_name] = field_value  # Field works, keep it
                print(f"   ‚úÖ Field '{field_name}' works")
                
            except Exception as e:
                print(f"   ‚ùå Field '{field_name}' failed: {e}")
                # This field doesn't exist in schema, skip it
                continue
        
        # Clean up test record
        try:
            client.table('roofmaxx_deals').delete().eq('deal_id', 999999997).execute()
        except:
            pass
            
        print(f"‚úÖ Working fields: {list(working_data.keys())}")
        return working_data
        
    except Exception as e:
        print(f"‚ùå Table schema test failed: {e}")
        return False

def run_working_sync(working_fields, good_endpoint, sample_data):
    """Run sync with only the fields that work."""
    
    print("üöÄ RUNNING SYNC WITH WORKING FIELDS")
    print("-" * 50)
    
    try:
        url = os.getenv('SUPABASE_URL')
        key = os.getenv('SUPABASE_SERVICE_ROLE_KEY')
        client = create_client(url, key)
        
        token = os.getenv('ROOFMAXX_CONNECT_TOKEN')
        base_url = os.getenv('ROOFMAXX_CONNECT_BASE_URL')
        dealer_id = os.getenv('ROOFMAXX_CONNECT_DEALER_ID')
        
        headers = {
            'Authorization': f'Bearer {token}',
            'Accept': 'application/json',
            'Content-Type': 'application/json'
        }
        
        # Fetch all deals using the working endpoint
        all_deals = []
        page = 1
        
        while True:
            try:
                print(f"üìÑ Fetching page {page}...")
                
                response = requests.get(
                    f"{base_url}{good_endpoint}",
                    headers=headers,
                    params={'page': page},
                    timeout=30
                )
                
                if response.status_code != 200:
                    print(f"‚ùå API Error: {response.status_code}")
                    break
                
                data = response.json()
                deals = data.get('data', [])
                
                if not deals:
                    break
                
                all_deals.extend(deals)
                print(f"   üìä Got {len(deals)} deals (total: {len(all_deals)})")
                
                # Check pagination
                meta = data.get('meta', {})
                if page >= meta.get('last_page', page):
                    break
                    
                page += 1
                time.sleep(0.3)
                
            except Exception as e:
                print(f"‚ùå Error on page {page}: {e}")
                break
        
        print(f"üéâ Fetched {len(all_deals)} total deals!")
        
        if not all_deals:
            print("‚ùå No deals to sync")
            return
        
        # Sync using only working fields
        print(f"üîÑ Syncing with fields: {list(working_fields.keys())}")
        
        synced_count = 0
        batch_size = 50
        
        for i in range(0, len(all_deals), batch_size):
            batch = all_deals[i:i + batch_size]
            batch_num = (i // batch_size) + 1
            total_batches = (len(all_deals) + batch_size - 1) // batch_size
            
            try:
                print(f"   üì¶ Batch {batch_num}/{total_batches}: {len(batch)} deals...")
                
                batch_data = []
                for deal in batch:
                    # Only use fields that work
                    deal_data = {'deal_id': deal.get('id')}
                    
                    # Add other fields if they exist in our working set
                    field_mapping = {
                        'dealer_id': lambda: int(dealer_id),
                        'deal_type': lambda: deal.get('dealType'),
                        'deal_lifecycle': lambda: deal.get('lifecycle'),
                        'deal_stage': lambda: deal.get('stage', {}).get('label') if isinstance(deal.get('stage'), dict) else str(deal.get('stage')),
                        'customer_first_name': lambda: deal.get('customerFirstName'),
                        'customer_last_name': lambda: deal.get('customerLastName'),
                        'city': lambda: deal.get('city'),
                        'state': lambda: deal.get('state'),
                    }
                    
                    for field, value_func in field_mapping.items():
                        if field in working_fields:
                            try:
                                value = value_func()
                                if value is not None:
                                    deal_data[field] = value
                            except:
                                pass
                    
                    batch_data.append(deal_data)
                
                # Upsert batch
                result = client.table('roofmaxx_deals').upsert(
                    batch_data,
                    on_conflict='deal_id'
                ).execute()
                
                synced_count += len(batch_data)
                print(f"   ‚úÖ Synced {len(batch_data)} deals")
                
            except Exception as e:
                print(f"   ‚ùå Batch {batch_num} error: {e}")
                continue
        
        print(f"\nüéä SYNC COMPLETE!")
        print(f"   ‚úÖ Deals synced: {synced_count:,}")
        
        # Analytics
        try:
            result = client.table('roofmaxx_deals').select('*', count='exact').execute()
            total = result.count
            
            print(f"\nüìä FINAL RESULTS:")
            print(f"   üìà Total deals: {total:,}")
            
            if total > 0:
                # Show sample data
                sample = client.table('roofmaxx_deals').select('*').limit(3).execute()
                print(f"\nüîç Sample records:")
                for i, record in enumerate(sample.data, 1):
                    print(f"   {i}. ID: {record.get('deal_id')} | Fields: {len(record)} | City: {record.get('city', 'N/A')}")
                
                print("\nüèÜ SUCCESS! Your deals are now in Supabase!")
                print("üçÜüí• TOM'S MIND = OFFICIALLY BLOWN!")
        
        except Exception as e:
            print(f"‚ùå Analytics error: {e}")
        
    except Exception as e:
        print(f"‚ùå Sync failed: {e}")

def main():
    """Main debug and fix process."""
    
    print("üîß DEBUG AND FIX ROOFMAXX ‚Üí SUPABASE")
    print("=" * 60)
    
    # Step 1: Debug API
    print("STEP 1: Debug API Connection")
    good_endpoint, sample_data = debug_api_connection()
    
    if not good_endpoint:
        print("‚ùå No working API endpoint found!")
        return
    
    print(f"\n‚úÖ Found working endpoint: {good_endpoint}")
    
    # Step 2: Fix table schema  
    print(f"\nSTEP 2: Fix Table Schema")
    working_fields = add_columns_to_table()
    
    if not working_fields:
        print("‚ùå Table schema issues!")
        return
    
    print(f"‚úÖ Working fields identified: {list(working_fields.keys())}")
    
    # Step 3: Run sync
    print(f"\nSTEP 3: Run Full Sync")
    run_working_sync(working_fields, good_endpoint, sample_data)
    
    print(f"\nüéØ üçÜüí• MISSION ACCOMPLISHED! üçÜüí•")

if __name__ == "__main__":
    main() 